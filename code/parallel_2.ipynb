{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepocessing libraries\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_coherence_score(model, text, dictionary, coherence):\n",
    "    \"\"\"\n",
    "    Calculates the coherence score of a topic model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : gensim.models.ldamodel.LdaModel\n",
    "        The LDA model.\n",
    "    corpus : list\n",
    "        The list of preprocesses stories.\n",
    "    dictionary : gensim.corpora.dictionary.Dictionary\n",
    "        The dictionary of the corpus.\n",
    "    Returns\n",
    "    -------\n",
    "    coherence_score : float\n",
    "        The coherence score of the topic model.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the word2vec score of the topic model\n",
    "    coherence_model_lda = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence=coherence)\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "    return coherence_score\n",
    "\n",
    "def get_cross_validation_data(data, n_topics_range, min_dfs, max_dfs, alphas, coherence):\n",
    "    \"\"\"\n",
    "    Performs cross validation to find the best hyperparameters for the topic model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.Series\n",
    "        The preprocessed stories.\n",
    "    n_topics_range : list\n",
    "        The range of number of topics to be considered.\n",
    "    min_dfs : list\n",
    "        The range of minimum document frequencies to be considered.\n",
    "    max_dfs : list\n",
    "        The range of maximum document frequencies to be considered.\n",
    "    alphas : list\n",
    "        The range of alpha values to be considered.\n",
    "    Returns\n",
    "    -------\n",
    "    cross_validation_data : pandas.DataFrame\n",
    "        The cross validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    cross_validation_data = pd.DataFrame(columns=['no_topics', 'min_df', 'max_df', 'alpha', coherence])\n",
    "    total_iterations = len(n_topics_range) * len(min_dfs) * len(max_dfs) * len(alphas)\n",
    "    progress_bar = tqdm(total=total_iterations, desc='Cross Validation', unit='model') # to show progress bar while iterating over the number of topics\n",
    "\n",
    "    # Grid search to find the best hyperparameters\n",
    "    for no_topics in n_topics_range:\n",
    "        for min_df in min_dfs:\n",
    "            for max_df in max_dfs:\n",
    "                for alpha in alphas:\n",
    "                    min_df_abs = min_df*data.size\n",
    "\n",
    "                    tokens_list = data[\"story\"].str.split().to_list()\n",
    "                    dictionary = Dictionary(tokens_list)\n",
    "                    dictionary.filter_extremes(no_below=min_df_abs, no_above=max_df)\n",
    "                    corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
    "\n",
    "                    lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=no_topics, alpha=alpha, random_state=0)\n",
    "                    coherence_score = get_coherence_score(lda, tokens_list, dictionary, coherence=coherence)\n",
    "\n",
    "                    cross_validation_data.loc[len(cross_validation_data)] = [no_topics, min_df, max_df, alpha, coherence_score]\n",
    "\n",
    "                    progress_bar.update(1)\n",
    "                    \n",
    "    progress_bar.close()\n",
    "    return cross_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross Validation: 100%|██████████| 30400/30400 [17:51:46<00:00,  2.12s/model]  \n"
     ]
    }
   ],
   "source": [
    "data_lemmatized = pd.read_csv(\"data/preprocessed_stories_lemmatized.csv\", header=None, names= [\"story\"])\n",
    "\n",
    "min_dfs = [i*0.01 for i in range(1, 11)]\n",
    "max_dfs = [i*0.01 for i in range(50, 10, -5)]\n",
    "alphas = [i*0.05 for i in range(1, 21)]\n",
    "no_topics_range = [i for i in range(2, 21)]\n",
    "\n",
    "cross_validation_data_cv = get_cross_validation_data(data_lemmatized, no_topics_range,     min_dfs, max_dfs, alphas, coherence='c_v')\n",
    "\n",
    "cross_validation_data_cv.to_csv(\"data/cross_validation_data_lemmatized_cv.csv\",    index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
