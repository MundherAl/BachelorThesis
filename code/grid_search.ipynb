{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as r\n",
    "\n",
    "# Prepocessing libraries\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_coherence_score(model, text, dictionary, coherence):\n",
    "    \"\"\"\n",
    "    Calculates the coherence score of a topic model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : gensim.models.ldamodel.LdaModel\n",
    "        The LDA model.\n",
    "    corpus : list\n",
    "        The list of preprocesses stories.\n",
    "    dictionary : gensim.corpora.dictionary.Dictionary\n",
    "        The dictionary of the corpus.\n",
    "    Returns\n",
    "    -------\n",
    "    coherence_score : float\n",
    "        The coherence score of the topic model.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the word2vec score of the topic model\n",
    "    coherence_model_lda = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence=coherence)\n",
    "    coherence_score = coherence_model_lda.get_coherence()\n",
    "    return coherence_score\n",
    "\n",
    "def grid_search(data, n_topics_range, min_dfs, max_dfs, alphas, etas, coherence):\n",
    "    \"\"\"\n",
    "    Performs a grid search to find the best hyperparameters for a topic model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.Series\n",
    "        The preprocessed stories.\n",
    "    n_topics_range : list\n",
    "        The range of number of topics to be considered.\n",
    "    min_dfs : list\n",
    "        The range of minimum document frequencies to be considered.\n",
    "    max_dfs : list\n",
    "        The range of maximum document frequencies to be considered.\n",
    "    alphas : list\n",
    "        The range of alpha values to be considered.\n",
    "    etas : list\n",
    "        The range of eta values to be considered.\n",
    "    coherence : str\n",
    "        The coherence score to be used.\n",
    "    Returns\n",
    "    -------\n",
    "    cross_validation_data : pandas.DataFrame\n",
    "        The cross validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    cross_validation_data = pd.DataFrame(columns=['no_topics', 'min_df', 'max_df', 'alpha', 'eta', coherence])\n",
    "    total_iterations = len(n_topics_range) * len(min_dfs) * len(max_dfs) * len(alphas) * len(etas)\n",
    "    progress_bar = tqdm(total=total_iterations, desc='Cross Validation', unit='model') # to show progress bar while iterating over the number of topics\n",
    "\n",
    "    # Grid search to find the best hyperparameters\n",
    "    for no_topics in n_topics_range:\n",
    "        for min_df in min_dfs:\n",
    "            for max_df in max_dfs:\n",
    "                for alpha in alphas:\n",
    "                    for eta in etas:\n",
    "                        min_df_abs = min_df*data.size\n",
    "\n",
    "                        tokens_list = data[\"story\"].str.split().to_list()\n",
    "                        dictionary = Dictionary(tokens_list)\n",
    "                        dictionary.filter_extremes(no_below=min_df_abs,     no_above=max_df)\n",
    "                        corpus = [dictionary.doc2bow(tokens) for tokens in  tokens_list]\n",
    "\n",
    "                        lda = LdaModel(corpus=corpus, id2word=dictionary,   num_topics=no_topics, alpha=alpha, random_state=0, eta=eta)\n",
    "                        coherence_score = get_coherence_score(lda, tokens_list,     dictionary, coherence=coherence)\n",
    "\n",
    "                        cross_validation_data.loc[len(cross_validation_data)] =     [no_topics, min_df, max_df, alpha, eta, coherence_score]\n",
    "\n",
    "                        progress_bar.update(1)\n",
    "                    \n",
    "    progress_bar.close()\n",
    "    return cross_validation_data\n",
    "\n",
    "def randomized_search(data, n_topics_range, min_dfs, max_dfs, alphas, etas, coherence, n_iter):\n",
    "    \"\"\"\n",
    "    Performs a randomized search to find the best hyperparameters for a topic model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.Series\n",
    "        The preprocessed stories.\n",
    "    n_topics_range : list\n",
    "        The range of number of topics to be considered.\n",
    "    min_dfs : list\n",
    "        The range of minimum document frequencies to be considered.\n",
    "    max_dfs : list\n",
    "        The range of maximum document frequencies to be considered.\n",
    "    alphas : list\n",
    "        The range of alpha values to be considered.\n",
    "    etas : list\n",
    "        The range of eta values to be considered.\n",
    "    coherence : str\n",
    "        The coherence score to be used.\n",
    "    n_iter : int\n",
    "        The number of iterations to be performed.\n",
    "    Returns\n",
    "    -------\n",
    "    cross_validation_data : pandas.DataFrame\n",
    "        The cross validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    cross_validation_data = pd.DataFrame(columns=['no_topics', 'min_df', 'max_df', 'alpha', 'eta', coherence])\n",
    "    total_iterations = n_iter\n",
    "    progress_bar = tqdm(total=total_iterations, desc='Cross Validation', unit='model') # to show progress bar while iterating over the number of topics\n",
    "\n",
    "    # Randomized search to find the best hyperparameters\n",
    "    for i in range(n_iter):\n",
    "        no_topics = r.choice(n_topics_range)\n",
    "        min_df = r.choice(min_dfs)\n",
    "        max_df = r.choice(max_dfs)\n",
    "        alpha = r.choice(alphas)\n",
    "        eta = r.choice(etas)\n",
    "\n",
    "        min_df_abs = min_df*data.size\n",
    "\n",
    "        tokens_list = data[\"story\"].str.split().to_list()\n",
    "        dictionary = Dictionary(tokens_list)\n",
    "        dictionary.filter_extremes(no_below=min_df_abs,     no_above=max_df)\n",
    "        corpus = [dictionary.doc2bow(tokens) for tokens in  tokens_list]\n",
    "\n",
    "        lda = LdaModel(corpus=corpus, id2word=dictionary,   num_topics=no_topics, alpha=alpha, random_state=0, eta=eta)\n",
    "        coherence_score = get_coherence_score(lda, tokens_list,     dictionary, coherence=coherence)\n",
    "\n",
    "        cross_validation_data.loc[len(cross_validation_data)] =     [no_topics, min_df, max_df, alpha, eta, coherence_score]\n",
    "\n",
    "        progress_bar.update(1)\n",
    "                    \n",
    "    progress_bar.close()\n",
    "    return cross_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross Validation: 100%|██████████| 5000/5000 [2:40:30<00:00,  1.93s/model]  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_topics</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>c_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.364727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.322121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.295055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.325234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.322238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.323228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.287306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.336565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.344310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.321243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      no_topics  min_df  max_df  alpha   eta       c_v\n",
       "0          11.0    0.03    0.46   0.35  0.09  0.364727\n",
       "1          14.0    0.04    0.17   0.16  0.24  0.322121\n",
       "2          10.0    0.04    0.40   0.25  0.16  0.295055\n",
       "3          13.0    0.10    0.49   0.15  0.05  0.325234\n",
       "4          13.0    0.03    0.17   0.31  0.16  0.322238\n",
       "...         ...     ...     ...    ...   ...       ...\n",
       "4995       10.0    0.09    0.32   0.46  0.29  0.323228\n",
       "4996       10.0    0.10    0.32   0.18  0.28  0.287306\n",
       "4997       12.0    0.05    0.50   0.37  0.09  0.336565\n",
       "4998       14.0    0.05    0.45   0.34  0.06  0.344310\n",
       "4999       15.0    0.02    0.40   0.31  0.06  0.321243\n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/preprocessed_stories.csv\", header=None, names= [\"story\"])\n",
    "\n",
    "min_dfs = [i*0.01 for i in range(1, 11)]\n",
    "max_dfs = [i*0.01 for i in range(50, 10, -1)]\n",
    "alphas = [i*0.01 for i in range(1, 51)]\n",
    "etas = [i*0.01 for i in range(1, 31)]\n",
    "no_topics_range = [i for i in range(2, 16)]\n",
    "\n",
    "cross_validation_data = randomized_search(data, no_topics_range, min_dfs, max_dfs, alphas, etas, coherence='c_v', n_iter=5000)\n",
    "\n",
    "cross_validation_data.to_csv(\"data/randomized_search_5000_iter.csv\", index=False)\n",
    "cross_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3867767142067709"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_data.c_v.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
